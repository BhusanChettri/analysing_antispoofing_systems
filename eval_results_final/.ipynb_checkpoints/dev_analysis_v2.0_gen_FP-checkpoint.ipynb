{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing False Positive Genuine files in Eval set - version 2.0 dataset\n",
    "\n",
    "> Get SLIME explanation for all those genuine FALSE Positive files. Meaning, these files are genuine files but it is misclassified as spoofed !! Looking at the SLIME explanation we try to infer meaning/correlation with our other observations !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top 10 genuine FP files\n",
    "\n",
    "         Gen prob     Spf Prob      Log Liklihood ratio\n",
    "                               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the prediction file\n",
    "# Predictions file that has three columns: genuin, spoofed prob and log likehood ratio\n",
    "\n",
    "pred_file='model_3sec_relu_0.5_run8/predictions/eval_prediction.txt'\n",
    "#new_pred_file = 'model_3sec_relu_0.5_run8/predictions/eval_prediction_with_index.txt'\n",
    "new_pred_file = 'predictions/eval_prediction_with_index.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open(pred_file) as f, open(new_pred_file,'w') as f2:\\n    i=0\\n    for line in f:\\n        f2.write(str(i)+' '+ line)\\n        #print(i)\\n        i+=1    \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new prediction file where we write index (starting from 0) as the first column\n",
    "# This way things become much easier\n",
    "\n",
    "'''\n",
    "with open(pred_file) as f, open(new_pred_file,'w') as f2:\n",
    "    i=0\n",
    "    for line in f:\n",
    "        f2.write(str(i)+' '+ line)\n",
    "        #print(i)\n",
    "        i+=1    \n",
    "'''\n",
    "\n",
    "# Above code is just used to append file index in the prediction file\n",
    "# Careful when re-running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate out predictions of genuine and spoofed files\n",
    "# Eval set set has first 1298 as genuine and remaining 12008 are spoofed\n",
    "# This is based on the protocal file I created which was used during training and feature extraction\n",
    "\n",
    "all_predictions = []\n",
    "all_gens = []\n",
    "all_spoofs = []\n",
    "\n",
    "with open(new_pred_file) as f:\n",
    "    all_predictions = [line.strip() for line in f]\n",
    "    \n",
    "all_gen_predictions = all_predictions[:1298]                 \n",
    "all_spf_predictions = all_predictions[1298:]                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298\n",
      "12008\n"
     ]
    }
   ],
   "source": [
    "print(len(all_gen_predictions))\n",
    "print(len(all_spf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfname='index_file_list/allGenIndexList_FP.txt'\\ncount=0\\nsplitIndex = 2                   # We want spoofed class probability\\npredList = all_gen_predictions   \\n\\n#print(len(predList))\\n\\nwith open(fname,'w') as f2:\\n    for items in predList:\\n        prob = items.strip().split(' ')[splitIndex]   \\n        if float(prob) > 0.9:\\n            print(items)\\n            count+=1\\n            f2.write(items+'\\n')            \\nprint(count)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all misclassified genuine files for which spoofed class got probability > 90%\n",
    "# the strongly correctly classified cases\n",
    "'''\n",
    "fname='index_file_list/allGenIndexList_FP.txt'\n",
    "count=0\n",
    "splitIndex = 2                   # We want spoofed class probability\n",
    "predList = all_gen_predictions   \n",
    "\n",
    "#print(len(predList))\n",
    "\n",
    "with open(fname,'w') as f2:\n",
    "    for items in predList:\n",
    "        prob = items.strip().split(' ')[splitIndex]   \n",
    "        if float(prob) > 0.9:\n",
    "            print(items)\n",
    "            count+=1\n",
    "            f2.write(items+'\\n')            \n",
    "print(count)\n",
    "'''\n",
    "\n",
    "\n",
    "# Careful when you re-run this code. It is use to take files with 90% probability to do analysis using slime !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 0.0190516 0.980948 -3.94137\n",
      "196 0.0188268 0.981173 -3.95347\n",
      "227 0.0961683 0.903832 -2.24054\n",
      "251 0.0683 0.9317 -2.6131\n",
      "535 0.0304232 0.969577 -3.46165\n",
      "892 0.0850959 0.914904 -2.37504\n",
      "1059 0.0632587 0.936741 -2.69517\n",
      "1268 0.0528581 0.947142 -2.88584\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat index_file_list/allGenIndexList_FP.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total misclassified genuine files where spoofed class got > 90% probability is = 8 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Time: The top two components from SLIME - False positive Genuine case\n",
    "\n",
    "Note, that under time analysis, we have cut our input spectrogram into 10 different temporal components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***300 mili seconds***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "time.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the explanation file to see the distribution\n",
    "\n",
    "file = 'top_two_explanation_indices/time/gen_FP_box.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top1_top2_list(file):\n",
    "    with open(file) as f:\n",
    "        top1 = [int(line.strip().split(' ')[0]) for line in f]\n",
    "    with open(file) as f:  \n",
    "        top2 = [int(line.strip().split(' ')[1]) for line in f]\n",
    "    return top1, top2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(datalist, key):\n",
    "    count=0\n",
    "    for i in range(0,len(datalist)):\n",
    "        if datalist[i] == key:\n",
    "            count+=1\n",
    "    return count            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_component_distribution(comps, predList, order):\n",
    "    print('Printing component weigting distribution for Top:', order)\n",
    "    for i in comps:\n",
    "        print('Component ' + str(i) + ' : ' + str(get_counts(predList, i)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the top1 components - given by SLIME (Time segmentation)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps=[0,1,2,3,4,5,6,7,8,9]    # In time we have 10 segments/components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 1\n",
      "Component 1 : 0\n",
      "Component 2 : 0\n",
      "Component 3 : 0\n",
      "Component 4 : 0\n",
      "Component 5 : 0\n",
      "Component 6 : 0\n",
      "Component 7 : 0\n",
      "Component 8 : 1\n",
      "Component 9 : 0\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "> ***Using the new boxplot*** (and also we corrected explanation index in our SLIME code)    \n",
    "\n",
    "    Component 0 : 1\n",
    "    Component 1 : 0\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 0\n",
    "    Component 6 : 0\n",
    "    Component 7 : 0\n",
    "    Component 8 : 1\n",
    "    Component 9 : 0\n",
    "    \n",
    "We only got two positive explanations from SLIME. For one audio file it favours for component 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Observation**\n",
    "> We see that out of these FP genuine files, the highest vote/explanation is favoured for component 0 (corresponding to 1000ms signal). ***It is similar to spoofed class behaviour***. In our spoofed class analysis we were making a hypothesis that the DTMF tones that were used for concatenating the signal is leared by the CNN for spoof class. These genuine files somehow exhibit those property and hence misclassified as spoofed (here we have taken 7 genuine files that were misclassified to check the distribution, with probability of spoofed class > 70%. We find for each of these files that highest explanation is for Component 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [81,4,289,47,283]   # Genuine misclassified as spoofed with >70% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [82,5,290,48,284]\n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000284.wav audio_files_hearing/genuine_FP/\n",
    "\n",
    "#ls audio_files_hearing/genuine_FP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Freq: The top two components from SLIME - True positive Genuine case\n",
    "\n",
    "Note, that under frequency analysis, we have cut our input spectrogram into 8 different frequency components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***1000 Hz frequency***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "frequency.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"frequency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get spectral explanation file\n",
    "\n",
    "file = 'top_two_explanation_indices/freq/gen_FP_box.txt' # using box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n",
      "6 -999\n",
      "6 -999\n",
      "6 3\n",
      "3 5\n",
      "6 -999\n",
      "6 3\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat 'top_two_explanation_indices/freq/gen_FP_box.txt' | head\n",
    "\n",
    "# the top two components 7 6 dominates the explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1 component distribution - Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps = [0,1,2,3,4,5,6,7]   # in Frequency we have 8 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 0\n",
      "Component 1 : 0\n",
      "Component 2 : 1\n",
      "Component 3 : 1\n",
      "Component 4 : 0\n",
      "Component 5 : 0\n",
      "Component 6 : 6\n",
      "Component 7 : 0\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Using new Box spectrograms**, and also we corrected the labels for explanation:\n",
    "\n",
    "Its same like before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing\n",
    "\n",
    "We take the other two remaining files also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000012.wav audio_files_hearing/genuine_FP/\n",
    "\n",
    "#ls audio_files_hearing/genuine_FP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Observations**\n",
    "\n",
    "> We find that all these 17 genuine files were misclassified as spoofed because these files exhibit the same property in high frequency regions that our spoofed class has learned. The frequency component 8 corresponding to 7000-8000 Hz, seems to get maximally activated for making the prediction. \n",
    "\n",
    " * This does not strongly corr-relate to our classes though. Our genuine class showed highest vote for component 7 and spoofed showed component 6. But, nevertheless, its shows that high frequency regions relate to class prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Summary from this study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 17 genuine audio files that were misclassified to be spoofed (with probability > 50%). Here we present brief summary under each methods.\n",
    "\n",
    "**Time segmentation**\n",
    "\n",
    "> The highest vote/explanation is favoured for component 3 (corresponding to 9000-1200ms signal). It is similar to genuine class behaviour, but we were expecting it to show properties that we found with spoofed class explanations. Note that spoofed class, under time analysis, give high weightage to first 300ms (which points to the fact that the DTMF tone is still causing the influence in spoofed class prediction !)\n",
    "\n",
    "**Frequency segmentation**\n",
    "\n",
    "> We find that all these 17 genuine files were misclassified as spoofed because these files exhibit the same property in high frequency regions that our spoofed class has learned. The frequency component 8 corresponding to 7000-8000 Hz, seems to get maximally activated for making the prediction. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Verify hypothesis about Spoofed class ( we show why genuine audio is misclassified as spoofed)\n",
    "\n",
    "We take all those genuine files in the development set that has been strongly misclassified as spoofed (more than 90% probability) and run SLIME to generate temporal and spectral explanation. We got 2 such files (out of 1298)\n",
    "\n",
    "\n",
    "Distribution of **temporal explanation** \n",
    "\n",
    "    Component 0 : 1\n",
    "    Component 1 : 0\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 0\n",
    "    Component 6 : 0\n",
    "    Component 7 : 0\n",
    "    Component 8 : 1\n",
    "    Component 9 : 0\n",
    "\n",
    "\n",
    "Distribution of **Spectral explanation**\n",
    "\n",
    "    Component 0 : 0\n",
    "    Component 1 : 0\n",
    "    Component 2 : 1\n",
    "    Component 3 : 1\n",
    "    Component 4 : 0\n",
    "    Component 5 : 0\n",
    "    Component 6 : 6\n",
    "    Component 7 : 0\n",
    "\n",
    "We get a clear cut explanation pointing towards information between 2-4kHz which exactly corresponds to the attributes of the spoofed class. But it shows a bit confusing pattern for 6 audio files that shows emphasis for higher frequencies (component 6)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
