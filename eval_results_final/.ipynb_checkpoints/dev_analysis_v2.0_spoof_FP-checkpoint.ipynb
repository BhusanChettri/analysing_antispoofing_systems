{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Spoofed False Positive files in EVAL set - version 2.0 dataset\n",
    "\n",
    "> Take those spoofed files from the development set that are misclassifed as genuine. Apply SLIME to understand and correlate the behaviour of classes !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the prediction file\n",
    "# Predictions file that has three columns: genuin, spoofed prob and log likehood ratio\n",
    "\n",
    "pred_file='model_3sec_relu_0.5_run8/predictions/eval_prediction.txt'\n",
    "#new_pred_file = 'model_3sec_relu_0.5_run8/predictions/eval_prediction_with_index.txt'\n",
    "new_pred_file = 'predictions/eval_prediction_with_index.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.999724 0.000276201 8.19411\n",
      "1 0.9991 0.000899707 7.01254\n",
      "2 0.999855 0.000145446 8.83556\n",
      "3 0.999999 8.39425e-07 13.9905\n",
      "4 0.999989 1.06374e-05 11.4511\n",
      "5 0.998049 0.00195086 6.23753\n",
      "6 0.882768 0.117232 2.01891\n",
      "7 0.9999 0.000100108 9.20916\n",
      "8 0.999961 3.94849e-05 10.1396\n",
      "9 0.999989 1.11043e-05 11.4082\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat predictions/eval_prediction_with_index.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate out predictions of genuine and spoofed files\n",
    "# Eval set set has first 1298 as genuine and remaining 12008 are spoofed\n",
    "# This is based on the protocal file I created which was used during training and feature extraction\n",
    "\n",
    "all_predictions = []\n",
    "all_gens = []\n",
    "all_spoofs = []\n",
    "\n",
    "with open(new_pred_file) as f:\n",
    "    all_predictions = [line.strip() for line in f]\n",
    "    \n",
    "all_gen_predictions = all_predictions[:1298]                 \n",
    "all_spf_predictions = all_predictions[1298:]                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298\n",
      "12008\n"
     ]
    }
   ],
   "source": [
    "print(len(all_gen_predictions))\n",
    "print(len(all_spf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfname='index_file_list/allSpoofIndexList_FP.txt'\\ncount=0\\nsplitIndex = 1                   # We want genuine probability\\npredList = all_spf_predictions   # use all_spf_predictions for spoofed case\\n\\nprint(len(predList))\\n\\nwith open(fname,'w') as f2:\\n    for items in predList:\\n        prob = items.strip().split(' ')[splitIndex]   \\n        if float(prob) > 0.9:\\n            #print(items)\\n            count+=1\\n            f2.write(items+'\\n')            \\nprint(count)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all spoofed files for which spoof class got probability > 90%\n",
    "# the strongly correctly classified cases\n",
    "'''\n",
    "fname='index_file_list/allSpoofIndexList_FP.txt'\n",
    "count=0\n",
    "splitIndex = 1                   # We want genuine probability\n",
    "predList = all_spf_predictions   # use all_spf_predictions for spoofed case\n",
    "\n",
    "print(len(predList))\n",
    "\n",
    "with open(fname,'w') as f2:\n",
    "    for items in predList:\n",
    "        prob = items.strip().split(' ')[splitIndex]   \n",
    "        if float(prob) > 0.9:\n",
    "            #print(items)\n",
    "            count+=1\n",
    "            f2.write(items+'\\n')            \n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7444\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat index_file_list/allSpoofIndexList_FP.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the development set, **we find 7444 (out of 12008) spoofed files that has been misclassified as genuine with more than 90% ** probability by the CNN end-to-end model. We take these 31 files and explore explanations from SLIME across time and frequency. This should exactly match with the class behaviour we found earlier for each classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Time: The top two components from SLIME - True positive Spoofed case\n",
    "\n",
    "Note, that under time analysis, we have cut our input spectrogram into 10 different temporal components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***300 mili seconds***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "time.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the explanation file\n",
    "\n",
    "file = 'top_two_explanation_indices/time/spoof_FP_box.txt'   # using signal box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "3 5\n",
      "5 1\n",
      "6 5\n",
      "5 3\n",
      "5 3\n",
      "2 6\n",
      "7 3\n",
      "2 5\n",
      "5 3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat top_two_explanation_indices/time/spoof_FP_box.txt  | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top1_top2_list(file):\n",
    "    with open(file) as f:\n",
    "        top1 = [int(line.strip().split(' ')[0]) for line in f]\n",
    "    with open(file) as f:  \n",
    "        top2 = [int(line.strip().split(' ')[1]) for line in f if int(line.strip().split(' ')[1]) != -999]\n",
    "    return top1, top2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7444\n",
      "7444\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(datalist, key):\n",
    "    count=0\n",
    "    for i in range(0,len(datalist)):\n",
    "        if datalist[i] == key:\n",
    "            count+=1\n",
    "    return count            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_component_distribution(comps, predList, order):\n",
    "    print('Printing component weigting distribution for Top:', order)\n",
    "    for i in comps:\n",
    "        print('Component ' + str(i) + ' : ' + str(get_counts(predList, i)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps=[0,1,2,3,4,5,6,7,8,9]    # In time we have 10 segments/components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 52\n",
      "Component 1 : 8\n",
      "Component 2 : 1151\n",
      "Component 3 : 2754\n",
      "Component 4 : 384\n",
      "Component 5 : 1832\n",
      "Component 6 : 1033\n",
      "Component 7 : 220\n",
      "Component 8 : 2\n",
      "Component 9 : 8\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the top1 components - given by SLIME (Time segmentation)\n",
    "\n",
    "    Component 0 : 52\n",
    "    Component 1 : 8\n",
    "    Component 2 : 1151\n",
    "    Component 3 : 2754\n",
    "    Component 4 : 384\n",
    "    Component 5 : 1832\n",
    "    Component 6 : 1033\n",
    "    Component 7 : 220\n",
    "    Component 8 : 2\n",
    "    Component 9 : 8\n",
    "    \n",
    "This behaviour/pattern completely matches with what we found for a Genuine class temporal segmentation analysis. There we found top components as: 3,4,5,6,7 (starting from 900ms). Here also we see same patter. Thus our analysis seems correct and answers too.    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [124,170,150,103,135]   # Spoof misclassified as genuine with >90% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [125,171,151,104,136] \n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000136.wav audio_files_hearing/spoof_FP/\n",
    "\n",
    "#ls audio_files_hearing/spoof_FP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Freq: The top two components from SLIME - True positive Spoofed\n",
    "\n",
    "Note, that under frequency analysis, we have cut our input spectrogram into 8 different frequency components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***1000 Hz frequency***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "frequency.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"frequency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the explanation file\n",
    "\n",
    "file = 'top_two_explanation_indices/freq/spoof_FP_box.txt'  # using signal box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 4\n",
      "7 6\n",
      "7 0\n",
      "7 6\n",
      "7 6\n",
      "7 6\n",
      "7 6\n",
      "5 0\n",
      "7 6\n",
      "7 6\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat 'top_two_explanation_indices/freq/spoof_FP_box.txt' | head\n",
    "\n",
    "# the top two components 7 6 dominates the explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7444\n",
      "7444\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1 component distribution - Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps = [0,1,2,3,4,5,6,7]   # in Frequency we have 8 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 32\n",
      "Component 1 : 0\n",
      "Component 2 : 0\n",
      "Component 3 : 0\n",
      "Component 4 : 0\n",
      "Component 5 : 330\n",
      "Component 6 : 45\n",
      "Component 7 : 7037\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> frequency distribution\n",
    "\n",
    "    Component 0 : 32\n",
    "    Component 1 : 0\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 330\n",
    "    Component 6 : 45\n",
    "    Component 7 : 7037\n",
    "    \n",
    "    \n",
    "From above we get a clear cut answer about why these spoofed audio files were misclassified as genuine. The frequency analysis shows strong emphasis on the higher frequency components (8000hz frequency information). This matches with our genuine class definition !!! Yay !    \n",
    "\n",
    "> Old specs without box (need to rerun as earlier we were using wrong labels for explanation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observation***\n",
    "\n",
    "Out of total 31 spoofed misclassified files with 90% probability for genuine class\n",
    " 1. 30 belongs to Component 8 (8000Hz, which is the class indicator for genuine class)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [671,942,134,139,160]   # Spoof misclassified as genuine with >90% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [672,943,135,140,161]\n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000161.wav audio_files_hearing/spoof_FP/\n",
    "\n",
    "#ls audio_files_hearing/spoof_FP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To further verify hypothesis about Genuine class (we show why spoofed audio is misclassified as genuine)\n",
    "\n",
    "We take all those spoofed files in the development set that has been strongly misclassified as genuine (more than 90% probability) and run SLIME to generate temporal and spectral explanation.\n",
    "\n",
    "> In the development set, **we find 7444 (out of 12008) spoofed files that has been misclassified as genuine with more than 90% ** probability by the CNN end-to-end model. We take these 7444 files and explore explanations from SLIME across time and frequency. This should exactly match with the class behaviour we found earlier for each classes.\n",
    "\n",
    "Distribution of **temporal explanation**  \n",
    "\n",
    "    Component 0 : 52\n",
    "    Component 1 : 8\n",
    "    Component 2 : 1151\n",
    "    Component 3 : 2754\n",
    "    Component 4 : 384\n",
    "    Component 5 : 1832\n",
    "    Component 6 : 1033\n",
    "    Component 7 : 220\n",
    "    Component 8 : 2\n",
    "    Component 9 : 8\n",
    "    \n",
    "This behaviour/pattern completely matches with what we found for a Genuine class temporal segmentation analysis. There we found top components as: 3,4,5,6,7 (starting from 900ms). Here also we see same patter. Thus our analysis seems correct and answers too.    \n",
    "\n",
    "\n",
    "Distribution of **Spectral explanation**\n",
    "\n",
    "    Component 0 : 32\n",
    "    Component 1 : 0\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 330\n",
    "    Component 6 : 45\n",
    "    Component 7 : 7037\n",
    "    \n",
    "    \n",
    "From above we get a clear cut answer about why these spoofed audio files were misclassified as genuine. The frequency analysis shows strong emphasis on the higher frequency components (8000hz frequency information). This matches with our genuine class definition !!! Yay !    \n",
    "\n",
    "We get a clear cut explanation pointing towards information above 7kHz which exactly corresponds to the attributes of the genuine class.\n",
    "\n",
    "> Thus from these 7444 misclassified spoofed files we proved the hypothesis and findings about our genuine class. In other words, genuine class is characterised by information above 7kHz present in the middle of the audio signal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
