{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Genuine files in Eval set - version 2.0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_train/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "ls /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_train/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the prediction file\n",
    "# Predictions file that has three columns: genuin, spoofed prob and log likehood ratio\n",
    "\n",
    "pred_file='model_3sec_relu_0.5_run8/predictions/eval_prediction.txt'\n",
    "#new_pred_file = 'model_3sec_relu_0.5_run8/predictions/eval_prediction_with_index.txt'\n",
    "new_pred_file = 'predictions/eval_prediction_with_index.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open(pred_file) as f, open(new_pred_file,'w') as f2:\\n    i=0\\n    for line in f:\\n        f2.write(str(i)+' '+ line)\\n        #print(i)\\n        i+=1    \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new prediction file where we write index (starting from 0) as the first column\n",
    "# This way things become much easier\n",
    "\n",
    "'''\n",
    "with open(pred_file) as f, open(new_pred_file,'w') as f2:\n",
    "    i=0\n",
    "    for line in f:\n",
    "        f2.write(str(i)+' '+ line)\n",
    "        #print(i)\n",
    "        i+=1    \n",
    "'''\n",
    "\n",
    "# Above code is just used to append file index in the prediction file\n",
    "# Careful when re-running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.999724 0.000276201 8.19411\n",
      "1 0.9991 0.000899707 7.01254\n",
      "2 0.999855 0.000145446 8.83556\n",
      "3 0.999999 8.39425e-07 13.9905\n",
      "4 0.999989 1.06374e-05 11.4511\n",
      "5 0.998049 0.00195086 6.23753\n",
      "6 0.882768 0.117232 2.01891\n",
      "7 0.9999 0.000100108 9.20916\n",
      "8 0.999961 3.94849e-05 10.1396\n",
      "9 0.999989 1.11043e-05 11.4082\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#cat model_3sec_relu_0.5_run8/predictions/eval_prediction_with_index.txt | tail\n",
    "cat predictions/eval_prediction_with_index.txt | head\n",
    "\n",
    "\n",
    " #Check the new prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate out predictions of genuine and spoofed files\n",
    "# Eval set set has first 1298 as genuine and remaining 12008 are spoofed\n",
    "# This is based on the protocal file I created which was used during training and feature extraction\n",
    "\n",
    "all_predictions = []\n",
    "all_gens = []\n",
    "all_spoofs = []\n",
    "\n",
    "with open(new_pred_file) as f:\n",
    "    all_predictions = [line.strip() for line in f]\n",
    "    \n",
    "all_gen_predictions = all_predictions[:1298]                 \n",
    "all_spf_predictions = all_predictions[1298:]                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298\n",
      "12008\n"
     ]
    }
   ],
   "source": [
    "print(len(all_gen_predictions))\n",
    "print(len(all_spf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfname='index_file_list/allGenIndexList_TP.txt'\\ncount=0\\nsplitIndex = 1     # 1 for genuine and 2 for spoofed (the third column)\\npredList = all_gen_predictions   # use all_spf_predictions for spoofed case\\n\\n#print(len(predList))\\n\\nwith open(fname,'w') as f2:\\n    for items in predList:\\n        prob = items.strip().split(' ')[splitIndex]   \\n        if float(prob) > 0.9:\\n            #print(items)\\n            count+=1\\n            f2.write(items+'\\n')            \\nprint(count)\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all genuine file for which genuine class got probability > 90%\n",
    "# the strongly correctly classified cases\n",
    "\n",
    "'''\n",
    "fname='index_file_list/allGenIndexList_TP.txt'\n",
    "count=0\n",
    "splitIndex = 1     # 1 for genuine and 2 for spoofed (the third column)\n",
    "predList = all_gen_predictions   # use all_spf_predictions for spoofed case\n",
    "\n",
    "#print(len(predList))\n",
    "\n",
    "with open(fname,'w') as f2:\n",
    "    for items in predList:\n",
    "        prob = items.strip().split(' ')[splitIndex]   \n",
    "        if float(prob) > 0.9:\n",
    "            #print(items)\n",
    "            count+=1\n",
    "            f2.write(items+'\\n')            \n",
    "print(count)\n",
    "'''\n",
    "# Careful when you re-run this code. It is use to take files with 90% probability to do analysis using slime !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat index_file_list/allGenIndexList_TP.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total genuine files we got with > 90% probability is = 1205 (out of 1298)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Take the top 10 genuine confident correctly classified files - high scores\n",
    "\n",
    "                               Gen prob     Spf Prob      Log Liklihood ratio\n",
    "    \n",
    "       \n",
    "**** Note when accessing via list or array, index 575 should be called as 574       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Time: The top two components from SLIME - True positive Genuine case\n",
    "\n",
    "Note, that under time analysis, we have cut our input spectrogram into 10 different temporal components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***300 mili seconds***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "time.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the temporal explanantion file produced by slime\n",
    "\n",
    "file = 'top_two_explanation_indices/time/gen_TP_box.txt'    #using box for spectrogram computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make sure to use the correct spectrogram for two cases !! ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "cat top_two_explanation_indices/time/gen_TP_box.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top1_top2_list(file):\n",
    "    with open(file) as f:\n",
    "        top1 = [int(line.strip().split(' ')[0]) for line in f]\n",
    "    with open(file) as f:  \n",
    "        top2 = [int(line.strip().split(' ')[1]) for line in f]\n",
    "    return top1, top2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205\n",
      "1205\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(datalist, key):\n",
    "    count=0\n",
    "    for i in range(0,len(datalist)):\n",
    "        if datalist[i] == key:\n",
    "            count+=1\n",
    "    return count            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_component_distribution(comps, predList, order):\n",
    "    print('Printing component weigting distribution for Top:', order)\n",
    "    for i in comps:\n",
    "        print('Component ' + str(i) + ' : ' + str(get_counts(predList, i)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the top1 components - given by SLIME (Time segmentation) - Genuine Class\n",
    "\n",
    "   \n",
    "    Component 0 : 39\n",
    "    Component 1 : 1\n",
    "    Component 2 : 172\n",
    "    Component 3 : 539\n",
    "    Component 4 : 52\n",
    "    Component 5 : 254\n",
    "    Component 6 : 126\n",
    "    Component 7 : 20\n",
    "    Component 8 : 0\n",
    "    Component 9 : 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39+1+172+539+52+254+126+20+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps=[0,1,2,3,4,5,6,7,8,9]    # In time we have 10 segments/components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 39\n",
      "Component 1 : 1\n",
      "Component 2 : 172\n",
      "Component 3 : 539\n",
      "Component 4 : 52\n",
      "Component 5 : 254\n",
      "Component 6 : 126\n",
      "Component 7 : 20\n",
      "Component 8 : 0\n",
      "Component 9 : 2\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we see that from 766 genuine TP audio files (that got scores > 0.5) we find that the largest number of times, SLIME gives highest weightage to Component 4 (271 times out of 766). Component 4 corresponds to 900-1200ms audio signal. This is then followed by Component 1 (136) which is the first 300 ms signal.\n",
    "\n",
    "Using signal Box also we found the same behaviour.\n",
    "\n",
    " * What to do next?\n",
    "We now pick those 271 audio files that got top1 as component 4 and try to find if we get some meaningful information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [506,480,757,208,481]   # Genuine True positive, >90% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [507,481,758,209,482]   # Genuine True positive, >90% probability\n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#ls /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000481.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000482.wav audio_files_hearing/genuine_TP/\n",
    "\n",
    "#play audio_files_hearing/genuine_TP/D_1000507.wav\n",
    "#ls audio_files_hearing/genuine_TP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Freq: The top two components from SLIME - True positive Genuine case\n",
    "\n",
    "Note, that under frequency analysis, we have cut our input spectrogram into 8 different frequency components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***1000 Hz frequency***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "frequency.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"frequency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the spectral explanation file\n",
    "\n",
    "file = 'top_two_explanation_indices/freq/gen_TP_box.txt'   #using signal box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cat 'top_two_explanation_indices/freq/gen_TP.txt' | head\n",
    "\n",
    "# the top two components 7 6 dominates the explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205\n",
      "1205\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1 component distribution - Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps = [0,1,2,3,4,5,6,7]   # in Frequency we have 8 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 1\n",
      "Component 1 : 0\n",
      "Component 2 : 0\n",
      "Component 3 : 0\n",
      "Component 4 : 0\n",
      "Component 5 : 26\n",
      "Component 6 : 0\n",
      "Component 7 : 1178\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+26+1178"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [571,455,387,202,708]   # Genuine True positive, >90% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [572,456,388,203,709]   # Genuine True positive, >90% probability\n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000709.wav audio_files_hearing/genuine_TP/\n",
    "\n",
    "#play audio_files_hearing/genuine_TP/D_1000507.wav\n",
    "#ls audio_files_hearing/genuine_TP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# On Evaluation set\n",
    "\n",
    "The evaluation set has 1298 genuine and 12008 spoofed examples. \n",
    "\n",
    "\n",
    "\n",
    "## What CNN has exploited about Genuine signal from the training data ?\n",
    "\n",
    "We first collect all the genuine audio files that has been strongly correctly classified with more than 90% probability by the CNN model. We find 1205 audio files (out of 1298). Next, we run SLIME algorithm on these 1205 audio files and generate temporal and spectral explanation distribution.\n",
    "\n",
    "Distribution of **temporal explanation** for \n",
    "\n",
    "    Component 0 : 39\n",
    "    Component 1 : 1\n",
    "    Component 2 : 172\n",
    "    Component 3 : 539\n",
    "    Component 4 : 52\n",
    "    Component 5 : 254\n",
    "    Component 6 : 126\n",
    "    Component 7 : 20\n",
    "    Component 8 : 0\n",
    "    Component 9 : 2\n",
    "    \n",
    "    \n",
    "Distribution of **Spectral explanation**\n",
    "\n",
    "    Component 0 : 1\n",
    "    Component 1 : 0\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 26\n",
    "    Component 6 : 0\n",
    "    Component 7 : 1178\n",
    "    \n",
    "    \n",
    "   \n",
    "On average, the explanation distribution show strong emphasis in the center of the 3 second audio signal. This further corresponds the region in audio signal where speech onset is detected. We find that majority of genuine audio files in the development data has non-speech frames in the beginning. On the spectral explanation distribution, it gives a very clear explanation that the model is looking at high frequency information above 7 kHz. \n",
    "\n",
    "> Therefore, what **conclusion** we get from above is that th model is identifying a file as genuine using information above 7 kHz mostly in the middle of the audio signal.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
