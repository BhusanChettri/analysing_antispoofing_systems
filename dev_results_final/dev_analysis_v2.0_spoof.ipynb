{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Spoofed files in dev set - version 2.0 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    " * Draw scatter plot of posteriors for our best CNN system to project the distribution of genuine and spoofed features\n",
    " * Do this for Development and evaluation set.\n",
    " * On Evaluation set you could do this plot seperately for different Replay configurations (total 57 will be too much though)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of file list for spoofed and genuine files in Development set for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) The top 10 spoofed confident correctly classified files : high scores\n",
    "\n",
    "                               Gen prob     Spf Prob      Log Liklihood ratio\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the prediction file\n",
    "# Predictions file that has three columns: genuin, spoofed prob and log likehood ratio\n",
    "\n",
    "pred_file='model_3sec_relu_0.5_run8/predictions/dev_prediction.txt'\n",
    "#new_pred_file = 'model_3sec_relu_0.5_run8/predictions/dev_prediction_with_index.txt'\n",
    "new_pred_file = 'predictions/dev_prediction_with_index.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.759194 0.240806 1.14826\n",
      "1 0.833182 0.166818 1.60835\n",
      "2 0.704341 0.295659 0.868054\n",
      "3 0.435833 0.564167 -0.25809\n",
      "4 0.143625 0.856375 -1.7855\n",
      "5 0.966915 0.0330851 3.37503\n",
      "6 0.693761 0.306239 0.81776\n",
      "7 0.946258 0.0537418 2.86832\n",
      "8 0.952323 0.0476765 2.99447\n",
      "9 0.9263 0.0737001 2.53119\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#cat model_3sec_relu_0.5_run8/predictions/dev_prediction_with_index.txt | head\n",
    "cat predictions/dev_prediction_with_index.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate out predictions of genuine and spoofed files\n",
    "\n",
    "all_predictions = []\n",
    "all_gens = []\n",
    "all_spoofs = []\n",
    "\n",
    "with open(new_pred_file) as f:\n",
    "    all_predictions = [line.strip() for line in f]\n",
    "    \n",
    "all_gen_predictions = all_predictions[:760]                    # first 760 files in dev are genuine\n",
    "all_spf_predictions = all_predictions[760:]                  # files from 761-1710 are spoofed examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "print(len(all_gen_predictions))\n",
    "print(len(all_spf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfname='index_file_list/allSpoofIndexList_TP.txt'\\ncount=0\\nsplitIndex = 2                   # 1 for genuine and 2 for spoofed (the third column)\\npredList = all_spf_predictions   # use all_spf_predictions for spoofed case\\n\\n#print(len(predList))\\n\\nwith open(fname,'w') as f2:\\n    for items in predList:\\n        prob = items.strip().split(' ')[splitIndex]   \\n        if float(prob) > 0.9:\\n            #print(items)\\n            count+=1\\n            f2.write(items+'\\n')            \\nprint(count)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all spoofed files for which spoof class got probability > 90%\n",
    "# the strongly correctly classified cases\n",
    "'''\n",
    "fname='index_file_list/allSpoofIndexList_TP.txt'\n",
    "count=0\n",
    "splitIndex = 2                   # 1 for genuine and 2 for spoofed (the third column)\n",
    "predList = all_spf_predictions   # use all_spf_predictions for spoofed case\n",
    "\n",
    "#print(len(predList))\n",
    "\n",
    "with open(fname,'w') as f2:\n",
    "    for items in predList:\n",
    "        prob = items.strip().split(' ')[splitIndex]   \n",
    "        if float(prob) > 0.9:\n",
    "            #print(items)\n",
    "            count+=1\n",
    "            f2.write(items+'\\n')            \n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat index_file_list/allSpoofIndexList_TP.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total examples we use = 733/950 (with spoofed class prob>90%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Point***\n",
    "> We select all those spoofed files that got spoofed probability > 90%. We have 733 spoofed files that we can use SLIME to get a reliable estimate for what the CNN might have learned about the spoofed class. Note that when running slime, for many files the SLIME returns no explanation coz we are only returning positive instance explanation. Thus we remove those files.\n",
    "\n",
    "> Therefore, these spoofed files have been classified with > 90% probability of being spoofed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Time: The top two components from SLIME - True positive Spoofed case\n",
    "\n",
    "Note, that under time analysis, we have cut our input spectrogram into 10 different temporal components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***300 mili seconds***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "time.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get temporal explanation from slime\n",
    "\n",
    "file = 'top_two_explanation_indices/time/spoof_TP_box.txt'  # with signal box for spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -999\n",
      "0 -999\n",
      "0 -999\n",
      "0 8\n",
      "0 -999\n",
      "0 -999\n",
      "0 -999\n",
      "0 1\n",
      "0 -999\n",
      "0 -999\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat top_two_explanation_indices/time/spoof_TP_box.txt  | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top1_top2_list(file):\n",
    "    with open(file) as f:\n",
    "        top1 = [int(line.strip().split(' ')[0]) for line in f]\n",
    "    with open(file) as f:  \n",
    "        top2 = [int(line.strip().split(' ')[1]) for line in f if int(line.strip().split(' ')[1]) != -999]\n",
    "    return top1, top2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(datalist, key):\n",
    "    count=0\n",
    "    for i in range(0,len(datalist)):\n",
    "        if datalist[i] == key:\n",
    "            count+=1\n",
    "    return count            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_component_distribution(comps, predList, order):\n",
    "    print('Printing component weigting distribution for Top:', order)\n",
    "    for i in comps:\n",
    "        print('Component ' + str(i) + ' : ' + str(get_counts(predList, i)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps=[0,1,2,3,4,5,6,7,8,9]    # In time we have 10 segments/components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 703\n",
      "Component 1 : 13\n",
      "Component 2 : 0\n",
      "Component 3 : 0\n",
      "Component 4 : 0\n",
      "Component 5 : 0\n",
      "Component 6 : 0\n",
      "Component 7 : 4\n",
      "Component 8 : 6\n",
      "Component 9 : 0\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the top1 components - given by SLIME (Time segmentation)\n",
    "\n",
    "> With correct indexing **we got 733/950 spoofed files with 90% probability**. SLIME returned 726 top1 positive explanation. Out of these 726 files we find component 0 to be higly dominating. This strongly confirms our findings:\n",
    "\n",
    "    Component 0 : 703\n",
    "    Component 1 : 13\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 0\n",
    "    Component 6 : 0\n",
    "    Component 7 : 4\n",
    "    Component 8 : 6\n",
    "    Component 9 : 0\n",
    "\n",
    "> *** Earlier when we were doing mistake (indexing issues) Using Signal box and creating new spectrograms***\n",
    "\n",
    "    Component 0 : 401\n",
    "    Component 1 : 10\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 0\n",
    "    Component 6 : 0\n",
    "    Component 7 : 1\n",
    "    Component 8 : 5\n",
    "    Component 9 : 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Observation ***\n",
    "> Top1 predictions favours the **first 300ms**. We get 703 votes (out of 733) from slime saying that it is looking at first 300 ms for spoofed class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [406,358,924,790,877]   # Spoof True positive, >90% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [407,359,925,791,878]   # Spoof True positive, >90% probability\n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000878.wav audio_files_hearing/spoof_TP/\n",
    "\n",
    "#ls audio_files_hearing/spoof_TP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysing Freq: The top two components from SLIME - True positive Spoofed\n",
    "\n",
    "Note, that under frequency analysis, we have cut our input spectrogram into 8 different frequency components/segments, where each segment correpsonds to\n",
    "\n",
    "> ***1000 Hz frequency***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "frequency.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how we cut the spectrogram in timexfrequency\n",
    "\n",
    "Image(\"frequency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get explanation from SLIME\n",
    "\n",
    "file = 'top_two_explanation_indices/freq/spoof_TP_box.txt'   # signal box -new specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "3 0\n",
      "0 3\n",
      "3 0\n",
      "0 3\n",
      "0 3\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat 'top_two_explanation_indices/freq/spoof_TP_box.txt' | head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top1 and top2 in seperate list\n",
    "top1, top2 = get_top1_top2_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733\n",
      "725\n"
     ]
    }
   ],
   "source": [
    "print(len(top1))\n",
    "print(len(top2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1 component distribution - Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comps = [0,1,2,3,4,5,6,7]   # in Frequency we have 8 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing component weigting distribution for Top: 1\n",
      "Component 0 : 85\n",
      "Component 1 : 3\n",
      "Component 2 : 0\n",
      "Component 3 : 528\n",
      "Component 4 : 0\n",
      "Component 5 : 86\n",
      "Component 6 : 31\n",
      "Component 7 : 0\n"
     ]
    }
   ],
   "source": [
    "# Print distribution on top1\n",
    "\n",
    "order = 1\n",
    "print_component_distribution(comps, top1, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With corrected indexing and using proper spoofed files to generate explanation: out of 733 top 90% probability files, 528 files vote for Component 3 that belong to frequency 3000-4000 Hz. \n",
    "\n",
    "    Component 0 : 85\n",
    "    Component 1 : 3\n",
    "    Component 2 : 0\n",
    "    Component 3 : 528\n",
    "    Component 4 : 0\n",
    "    Component 5 : 86\n",
    "    Component 6 : 31\n",
    "    Component 7 : 0\n",
    "\n",
    "\n",
    "> (with indexing mistake) Using new spectrograms, ***with signal box***\n",
    "\n",
    "    Component 0 : 158\n",
    "    Component 1 : 5\n",
    "    Component 2 : 9\n",
    "    Component 3 : 415\n",
    "    Component 4 : 0\n",
    "    Component 5 : 29\n",
    "    Component 6 : 15\n",
    "    Component 7 : 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "#plt.plot(top1,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observation***\n",
    "> We see that under frequency analysis, the top explanation appears to be favouring frequency bin 3000-4000Hz for component 3. This is different from what we saw for the genuine class (that favours highly for component 8, 7000-8000Hz)\n",
    "\n",
    "***Out of total 733 spoofed files***\n",
    " 1. 528 belongs to 4000Hz\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation: **\n",
    "> In SLIME code, as I was returning two indices, for spoofed files SLIME was only returning positive index, which in many cases was only one, therefore, I put -999 as the second value (just not to break the code and make changes)\n",
    "\n",
    " * It give high importance to component 0, 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick 5 audio files for hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_5_ids = [891,153,271,390,647]   # Spoof True positive, >90% probability\n",
    "#add 1 to each to access correct file index in real world\n",
    "\n",
    "#random_5_ids = [892,154,272,391,648]   # Spoof True positive, >90% probability\n",
    "#base='/homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cp /homes/bc305/myphd/datasets/ASVSpoof2017_v2.0/ASVspoof2017_V2_dev/D_1000648.wav audio_files_hearing/spoof_TP/\n",
    "\n",
    "#ls audio_files_hearing/spoof_TP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Summary from this study (considering only top1 explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time segmentation**\n",
    "\n",
    ">We segmented spectrogram into 10 super-samples (components), each of 1000ms, and ran SLIME to generate explanations using 5000 samples. We find that among 655 True-positive spoofed files (with probability > 90%), the highest influence is shown for **component 0** that corresponds to **first 300ms**. We get 234 votes from slime.\n",
    "\n",
    "\n",
    "**Frequency segmentation**\n",
    "> We segmented the spectrograms into 8 different frequency bins, each corresponding to 1000Hz and ran SLIME. In this case, we see that the top explanation appears to be favouring frequency bin 7000Hz. The next two frequency information that influences are 4000Hz and 1000Hz.\n",
    "\n",
    "\n",
    "> ***NOTE: In genuine case we got highest vote for 8000Hz bin***\n",
    "\n",
    "\n",
    "** Correlation between time,frequency **\n",
    "\n",
    "> Under time analysis we found that the model is highly influenced for first 300ms signal. This relates to the fact that the model seem to exploit information related to DTMF tone that was used for concatenating the original RedDots genuine signal to create spoofed counterparts. SLIME seems to explain this very fact, as we find 234 votes for the spoofed signals with probability greater than 90%. We may still want to double check this fact by just taking the spoofed files with highest probability !\n",
    "\n",
    "> Next interesting observation we find is by doing frequency analysis, we see that spoofed class is looking at the high frequency\n",
    "\n",
    "> To write properly !!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> We select all those spoofed files that got spoofed probability > 90%. We have 733 spoofed files that we can use SLIME to get a reliable estimate for what the CNN might have learned about the spoofed class. Note that when running slime, for many files the SLIME returns no explanation coz we are only returning positive instance explanation. Thus we remove those files.\n",
    "\n",
    "> Therefore, these spoofed files have been classified with > 90% probability of being spoofed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What CNN has exploited about Spoofed signal from the training data ?\n",
    "\n",
    "We first collect all the spoofed audio files that has been strongly correctly classified with more than 90% probability by the CNN model. We find 733 audio files (out of 950). Next, we run SLIME algorithm on these files and generate temporal and spectral explanations.\n",
    "\n",
    "\n",
    "On the temporal side we get 726 (out of 733 test files) as SLIME did  not find positive explanation for 7 files. Distribution shown below are for 726 spoofed files classified correctly with > 90% probabiliy.\n",
    "Distribution of **temporal explanation**  \n",
    "\n",
    "    Component 0 : 703\n",
    "    Component 1 : 13\n",
    "    Component 2 : 0\n",
    "    Component 3 : 0\n",
    "    Component 4 : 0\n",
    "    Component 5 : 0\n",
    "    Component 6 : 0\n",
    "    Component 7 : 4\n",
    "    Component 8 : 6\n",
    "    Component 9 : 0\n",
    "    \n",
    "See, we get strong vote (703 files out of 726) for component 0. First two components    \n",
    "\n",
    "Distribution of **Spectral explanation**\n",
    "\n",
    "    Component 0 : 85\n",
    "    Component 1 : 3\n",
    "    Component 2 : 0\n",
    "    Component 3 : 528\n",
    "    Component 4 : 0\n",
    "    Component 5 : 86\n",
    "    Component 6 : 31\n",
    "    Component 7 : 0\n",
    "\n",
    "   \n",
    "  \n",
    "On average, the temporal explanation distribution show strong emphasis in the inital frames. We find majority of spoofed audio files has speech onset present in first few mili seconds. This strongly attributes to the explanation distribution shown by SLIME in frequency. The highest influence is shown for spectral component representing information between 3-4 kHz. \n",
    "\n",
    "> This might also correspond to the way replayed database was collected, where DTMF tone was used as a marker to concatenate series of short audio utterance and replayed under different replay configurations. So, when the replayed utterance was cut back to seperate out these individual segments the DTMF tone was removed while also removing the initial silence frames thus leaving a strong cue between a genuine and a spoofed class that the deep models seem to be cleverly exploiting for decision making between two classes of data. (Have to double check these statements, as there is no reference paper describing how actually data was collected. This was what Tomi had told me long back. Writing it here just for my reference)\n",
    "\n",
    "\n",
    "> Therefore, what **conclusion** we get from above is that the model is identifying a file as spoofed using speech information in 3-4 kHz frequency in the initial few frames of the audio signal.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
